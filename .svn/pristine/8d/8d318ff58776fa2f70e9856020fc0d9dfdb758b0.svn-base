import OpenAI from 'openai';
import type { AIProvider, AIModel, AIResponse, Analysis, ConversationContext, AIOptions, AIProviderStatus, RichTranslation } from '../types';
import { getAnalysisPrompt, getRichTranslationPrompt, getUnifiedAnalysisPrompt } from '../prompts';

// OpenAI Chat Completions Provider (We manage conversation history)
export class OpenAIChatProvider implements AIProvider {
  id = 'openai-chat';
  name = 'OpenAI (Chat)';
  type = 'cloud' as const;
  contextMode = 'manual' as const;
  
  models: AIModel[] = [
    { id: 'gpt-4o-mini', name: 'GPT-4o Mini', contextWindow: 128000, description: 'Fast and affordable' },
    { id: 'gpt-4o', name: 'GPT-4o', contextWindow: 128000, description: 'Most capable' },
    { id: 'gpt-4-turbo', name: 'GPT-4 Turbo', contextWindow: 128000, description: 'High performance' },
    { id: 'gpt-3.5-turbo', name: 'GPT-3.5 Turbo', contextWindow: 16385, description: 'Legacy, fast' },
  ];

  private client: OpenAI | null = null;
  private status: AIProviderStatus = {
    initialized: false,
    loading: false,
  };

  async initialize(): Promise<void> {
    const apiKey = process.env.OPENAI_API_KEY;
    
    if (!apiKey) {
      this.status = {
        initialized: false,
        loading: false,
        error: 'OpenAI API key not configured',
      };
      return;
    }

    this.client = new OpenAI({ apiKey });
    this.status = {
      initialized: true,
      loading: false,
    };
  }

  async chat(context: ConversationContext, message: string, options?: AIOptions): Promise<AIResponse> {
    if (!this.client) {
      throw new Error('OpenAI client not initialized');
    }

    // Build messages array with full history
    const messages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }> = [
      { role: 'system', content: context.systemPrompt },
    ];

    // Add summary if available
    if (context.summary) {
      messages.push({
        role: 'system',
        content: `CONVERSATION SUMMARY (earlier messages):\n${context.summary}`,
      });
    }

    // Add conversation history
    messages.push(...context.messages);

    // Add new user message
    messages.push({ role: 'user', content: message });

    const response = await this.client.chat.completions.create({
      model: options?.model || 'gpt-4o-mini',
      messages,
      temperature: options?.temperature ?? 0.7,
      max_tokens: options?.maxTokens ?? 500,
    });

    const choice = response.choices[0];
    
    return {
      content: choice.message.content || '',
      usage: response.usage ? {
        promptTokens: response.usage.prompt_tokens,
        completionTokens: response.usage.completion_tokens,
        totalTokens: response.usage.total_tokens,
      } : undefined,
    };
  }

  async analyze(context: ConversationContext, userMessage: string, options?: AIOptions): Promise<Analysis> {
    if (!this.client) {
      throw new Error('OpenAI client not initialized');
    }

    // CURSOR: If audio is provided, use unified analysis (one AI call for everything)
    if (options?.audioBase64 && options?.audioFormat) {
      return this.analyzeWithAudio(context, options);
    }

    // CURSOR: Text-only analysis (no audio available)
    return this.analyzeTextOnly(context, userMessage, options);
  }

  // CURSOR: Unified audio analysis - sends audio + chat history in ONE call
  // AI listens to audio, transcribes, and analyzes grammar/vocabulary/relevance/pronunciation together
  private async analyzeWithAudio(context: ConversationContext, options: AIOptions): Promise<Analysis> {
    const recentMessages = context.messages.slice(-10);
    const prompt = getUnifiedAnalysisPrompt(options.motherLanguage, options.learningLanguage);

    const conversationContext = `${context.summary ? `EARLIER CONVERSATION SUMMARY:\n${context.summary}\n\n` : ''}RECENT CONVERSATION:\n${recentMessages.map(m => `${m.role}: ${m.content}`).join('\n')}`;

    // CURSOR: Use audio model for unified analysis
    const model = options.model && options.model.includes('audio')
      ? options.model
      : 'gpt-4o-audio-preview';

    console.log('[OpenAI Unified Analysis] Using model:', model, 'with audio');
    console.log('[OpenAI Unified Analysis] Context messages:', recentMessages.length);

    const response = await this.client!.chat.completions.create({
      model,
      messages: [
        {
          role: 'system',
          content: `You are a language learning analysis assistant that analyzes audio recordings.
CRITICAL: Your response must be ONLY valid JSON. No explanations, no conversational text, no markdown.
Start your response with { and end with }. Nothing else.`
        },
        {
          role: 'user',
          content: [
            { type: 'text', text: `${prompt}\n\n${conversationContext}\n\nNow listen to the audio and analyze it. REMEMBER: Respond with JSON only. Start with { immediately.` },
            { type: 'input_audio', input_audio: { data: options.audioBase64!, format: options.audioFormat! } },
          ] as unknown as string,
        },
      ],
      temperature: 0.3,
      max_tokens: 1500,
    });

    const content = response.choices[0].message.content || '{}';
    console.log('[OpenAI Unified Analysis] Raw response:', content.substring(0, 200) + '...');

    try {
      const parsed = JSON.parse(content);

      // CURSOR: Build unified analysis with pronunciation embedded
      const analysis: Analysis = {
        grammarScore: parsed.grammarScore ?? parsed.grammar_score ?? 70,
        grammarErrors: Array.isArray(parsed.grammarErrors) ? parsed.grammarErrors
          : Array.isArray(parsed.grammar_errors) ? parsed.grammar_errors
          : [],
        vocabularyScore: parsed.vocabularyScore ?? parsed.vocabulary_score ?? 70,
        vocabularySuggestions: Array.isArray(parsed.vocabularySuggestions) ? parsed.vocabularySuggestions
          : Array.isArray(parsed.vocabulary_suggestions) ? parsed.vocabulary_suggestions
          : [],
        relevanceScore: parsed.relevanceScore ?? parsed.relevance_score ?? 80,
        relevanceFeedback: parsed.relevanceFeedback ?? parsed.relevance_feedback ?? undefined,
        fluencyScore: 0, // Not used in unified analysis
        overallFeedback: parsed.overallFeedback ?? parsed.overall_feedback ?? 'Good effort!',
        alternativePhrasings: Array.isArray(parsed.alternativePhrasings) ? parsed.alternativePhrasings
          : Array.isArray(parsed.alternative_phrasings) ? parsed.alternative_phrasings
          : [],
        // CURSOR: Pronunciation is part of the unified result
        pronunciation: {
          pronunciationScore: parsed.pronunciationScore ?? parsed.pronunciation_score ?? 70,
          transcribedText: parsed.transcribedText ?? parsed.transcribed_text ?? '',
          mispronunciations: Array.isArray(parsed.mispronunciations)
            ? parsed.mispronunciations.map((item: { word?: string; heardAs?: string; correctPronunciation?: string }) => ({
                word: item.word ?? '',
                heardAs: item.heardAs ?? '',
                correctPronunciation: item.correctPronunciation ?? '',
              }))
            : [],
          pronunciationFeedback: parsed.pronunciationFeedback ?? parsed.pronunciation_feedback ?? '',
        },
      };

      console.log('[OpenAI Unified Analysis] Result - Grammar:', analysis.grammarScore, 'Vocab:', analysis.vocabularyScore, 'Relevance:', analysis.relevanceScore, 'Pronunciation:', analysis.pronunciation?.pronunciationScore);
      console.log('[OpenAI Unified Analysis] Transcribed:', analysis.pronunciation?.transcribedText);
      return analysis;
    } catch (e) {
      console.error('[OpenAI Unified Analysis] JSON parse failed:', e);
      console.error('[OpenAI Unified Analysis] Content was:', content);
      return {
        grammarScore: 70,
        grammarErrors: [],
        vocabularyScore: 70,
        vocabularySuggestions: [],
        relevanceScore: 80,
        fluencyScore: 0,
        overallFeedback: 'Unable to parse analysis.',
        alternativePhrasings: [],
      };
    }
  }

  // CURSOR: Text-only analysis (original behavior, no audio)
  private async analyzeTextOnly(context: ConversationContext, userMessage: string, options?: AIOptions): Promise<Analysis> {
    const recentMessages = context.messages.slice(-10);

    const prompt = `${getAnalysisPrompt(options?.motherLanguage, options?.learningLanguage)}

${context.summary ? `EARLIER CONVERSATION SUMMARY:\n${context.summary}\n` : ''}

RECENT CONVERSATION:
${recentMessages.map(m => `${m.role}: ${m.content}`).join('\n')}

MESSAGE TO ANALYZE:
${userMessage}`;

    const response = await this.client!.chat.completions.create({
      model: options?.model || 'gpt-4o-mini',
      messages: [
        { role: 'system', content: 'You are a language learning analysis assistant. Respond only with valid JSON.' },
        { role: 'user', content: prompt },
      ],
      temperature: 0.3,
      max_tokens: 1000,
      response_format: { type: 'json_object' },
    });

    const content = response.choices[0].message.content || '{}';
    console.log('[OpenAI Text Analysis] Raw response:', content.substring(0, 200));

    try {
      const parsed = JSON.parse(content);
      return {
        grammarScore: parsed.grammarScore ?? parsed.grammar_score ?? 70,
        grammarErrors: Array.isArray(parsed.grammarErrors) ? parsed.grammarErrors
          : Array.isArray(parsed.grammar_errors) ? parsed.grammar_errors
          : [],
        vocabularyScore: parsed.vocabularyScore ?? parsed.vocabulary_score ?? 70,
        vocabularySuggestions: Array.isArray(parsed.vocabularySuggestions) ? parsed.vocabularySuggestions
          : Array.isArray(parsed.vocabulary_suggestions) ? parsed.vocabulary_suggestions
          : [],
        relevanceScore: parsed.relevanceScore ?? parsed.relevance_score ?? 80,
        relevanceFeedback: parsed.relevanceFeedback ?? parsed.relevance_feedback ?? undefined,
        fluencyScore: 0,
        overallFeedback: parsed.overallFeedback ?? parsed.overall_feedback ?? 'Good effort!',
        alternativePhrasings: Array.isArray(parsed.alternativePhrasings) ? parsed.alternativePhrasings
          : Array.isArray(parsed.alternative_phrasings) ? parsed.alternative_phrasings
          : [],
      };
    } catch (e) {
      console.error('[OpenAI Text Analysis] JSON parse failed:', e);
      return {
        grammarScore: 70,
        grammarErrors: [],
        vocabularyScore: 70,
        vocabularySuggestions: [],
        relevanceScore: 80,
        fluencyScore: 0,
        overallFeedback: 'Unable to parse detailed analysis.',
        alternativePhrasings: [],
      };
    }
  }

  // CURSOR: Rich translation with definition, usage examples, and type classification
  async richTranslate(
    text: string,
    learningLanguage: string,
    motherLanguage: string,
    options?: AIOptions
  ): Promise<RichTranslation> {
    if (!this.client) {
      throw new Error('OpenAI client not initialized');
    }

    const prompt = getRichTranslationPrompt(text, learningLanguage, motherLanguage);

    const response = await this.client.chat.completions.create({
      model: options?.model || 'gpt-4o-mini',
      messages: [
        { role: 'system', content: 'You are a language learning assistant providing detailed translations. Respond only with valid JSON.' },
        { role: 'user', content: prompt },
      ],
      temperature: 0.3,
      max_tokens: options?.maxTokens ?? 500,
      response_format: { type: 'json_object' },
    });

    const content = response.choices[0].message.content || '{}';
    
    console.log('[OpenAI RichTranslate] Raw response:', content);
    
    try {
      const parsed = JSON.parse(content);
      
      // CURSOR: Normalize response with fallbacks
      const richTranslation: RichTranslation = {
        translation: parsed.translation || text,
        type: parsed.type || 'word',
        definition: parsed.definition || parsed.translation || '',
        usageExamples: Array.isArray(parsed.usageExamples) ? parsed.usageExamples
          : Array.isArray(parsed.usage_examples) ? parsed.usage_examples
          : Array.isArray(parsed.examples) ? parsed.examples
          : [],
        notes: parsed.notes || undefined,
        formality: parsed.formality || 'neutral',
      };
      
      return richTranslation;
    } catch (e) {
      console.error('[OpenAI RichTranslate] JSON parse failed:', e);
      // CURSOR: Return minimal fallback
      return {
        translation: text,
        type: 'word',
        definition: '',
        usageExamples: [],
        formality: 'neutral',
      };
    }
  }

  async isAvailable(): Promise<boolean> {
    return !!process.env.OPENAI_API_KEY;
  }

  getStatus(): AIProviderStatus {
    return this.status;
  }
}

// Export singleton instance
export const openAIChatProvider = new OpenAIChatProvider();
