import OpenAI from 'openai';
import type { AIProvider, AIModel, AIResponse, Analysis, ConversationContext, AIOptions, AIProviderStatus, ChatMessage, RichTranslation } from '../types';
import { getAnalysisPrompt, getRichTranslationPrompt, getUnifiedAnalysisPrompt } from '../prompts';

// OpenAI Assistants API Provider (OpenAI manages conversation history)
export class OpenAIAssistantProvider implements AIProvider {
  id = 'openai-assistant';
  name = 'OpenAI (Assistants)';
  type = 'cloud' as const;
  contextMode = 'managed' as const;
  
  models: AIModel[] = [
    { id: 'gpt-4o-mini', name: 'GPT-4o Mini', contextWindow: 128000, description: 'Fast and affordable' },
    { id: 'gpt-4o', name: 'GPT-4o', contextWindow: 128000, description: 'Most capable' },
  ];

  private client: OpenAI | null = null;
  private assistantId: string | null = null;
  private status: AIProviderStatus = {
    initialized: false,
    loading: false,
  };

  async initialize(): Promise<void> {
    const apiKey = process.env.OPENAI_API_KEY;
    
    if (!apiKey) {
      this.status = {
        initialized: false,
        loading: false,
        error: 'OpenAI API key not configured',
      };
      return;
    }

    this.client = new OpenAI({ apiKey });
    this.status = {
      initialized: true,
      loading: false,
    };
  }

  // Set or create assistant
  async setAssistant(assistantId?: string, systemPrompt?: string): Promise<string> {
    if (!this.client) {
      throw new Error('OpenAI client not initialized');
    }

    if (assistantId) {
      // Verify assistant exists
      try {
        await this.client.beta.assistants.retrieve(assistantId);
        this.assistantId = assistantId;
        return assistantId;
      } catch {
        // Assistant doesn't exist, create new one
      }
    }

    // Create new assistant
    const assistant = await this.client.beta.assistants.create({
      name: 'Lanqua Language Tutor',
      instructions: systemPrompt || 'You are a friendly language tutor helping someone learn English.',
      model: 'gpt-4o-mini',
    });

    this.assistantId = assistant.id;
    return assistant.id;
  }

  async createThread(): Promise<string> {
    if (!this.client) {
      throw new Error('OpenAI client not initialized');
    }

    const thread = await this.client.beta.threads.create();
    return thread.id;
  }

  async getThreadMessages(threadId: string): Promise<ChatMessage[]> {
    if (!this.client) {
      throw new Error('OpenAI client not initialized');
    }

    const messages = await this.client.beta.threads.messages.list(threadId);
    
    return messages.data.reverse().map(msg => ({
      role: msg.role as 'user' | 'assistant',
      content: msg.content[0]?.type === 'text' ? msg.content[0].text.value : '',
    }));
  }

  async chat(context: ConversationContext, message: string, options?: AIOptions): Promise<AIResponse> {
    if (!this.client) {
      throw new Error('OpenAI client not initialized');
    }

    if (!context.threadId) {
      throw new Error('Thread ID required for Assistants API');
    }

    if (!this.assistantId) {
      await this.setAssistant(undefined, context.systemPrompt);
    }

    // Add message to thread
    await this.client.beta.threads.messages.create(context.threadId, {
      role: 'user',
      content: message,
    });

    // Create and poll run
    const run = await this.client.beta.threads.runs.createAndPoll(context.threadId, {
      assistant_id: this.assistantId!,
      model: options?.model,
    });

    if (run.status === 'completed') {
      const messages = await this.client.beta.threads.messages.list(context.threadId);
      const lastMessage = messages.data[0];
      
      return {
        content: lastMessage.content[0]?.type === 'text' ? lastMessage.content[0].text.value : '',
        usage: run.usage ? {
          promptTokens: run.usage.prompt_tokens,
          completionTokens: run.usage.completion_tokens,
          totalTokens: run.usage.total_tokens,
        } : undefined,
      };
    }

    throw new Error(`Run failed with status: ${run.status}`);
  }

  async analyze(context: ConversationContext, userMessage: string, options?: AIOptions): Promise<Analysis> {
    if (!this.client) {
      throw new Error('OpenAI client not initialized');
    }

    // CURSOR: If audio is provided, use unified analysis (one AI call for everything)
    if (options?.audioBase64 && options?.audioFormat) {
      return this.analyzeWithAudio(context, options);
    }

    // CURSOR: Text-only analysis
    const recentMessages = context.messages.slice(-10);
    const prompt = `${getAnalysisPrompt(options?.motherLanguage, options?.learningLanguage)}

RECENT CONVERSATION:
${recentMessages.map(m => `${m.role}: ${m.content}`).join('\n')}

MESSAGE TO ANALYZE:
${userMessage}`;

    const response = await this.client.chat.completions.create({
      model: options?.model || 'gpt-4o-mini',
      messages: [
        { role: 'system', content: 'You are a language learning analysis assistant. Respond only with valid JSON.' },
        { role: 'user', content: prompt },
      ],
      temperature: 0.3,
      max_tokens: 1000,
      response_format: { type: 'json_object' },
    });

    const content = response.choices[0].message.content || '{}';
    try {
      return JSON.parse(content) as Analysis;
    } catch {
      return {
        grammarScore: 70, grammarErrors: [], vocabularyScore: 70,
        vocabularySuggestions: [], relevanceScore: 80, fluencyScore: 0,
        overallFeedback: 'Unable to parse detailed analysis.',
        alternativePhrasings: [],
      };
    }
  }

  // CURSOR: Unified audio analysis - sends audio + chat history in ONE call
  private async analyzeWithAudio(context: ConversationContext, options: AIOptions): Promise<Analysis> {
    const recentMessages = context.messages.slice(-10);
    const prompt = getUnifiedAnalysisPrompt(options.motherLanguage, options.learningLanguage);
    const conversationContext = `${context.summary ? `EARLIER CONVERSATION SUMMARY:\n${context.summary}\n\n` : ''}RECENT CONVERSATION:\n${recentMessages.map(m => `${m.role}: ${m.content}`).join('\n')}`;

    const model = options.model && options.model.includes('audio')
      ? options.model
      : 'gpt-4o-audio-preview';

    const response = await this.client!.chat.completions.create({
      model,
      messages: [
        {
          role: 'system',
          content: `You are a language learning analysis assistant that analyzes audio recordings.
CRITICAL: Your response must be ONLY valid JSON. No explanations, no conversational text, no markdown.
Start your response with { and end with }. Nothing else.`
        },
        {
          role: 'user',
          content: [
            { type: 'text', text: `${prompt}\n\n${conversationContext}\n\nNow listen to the audio and analyze it. REMEMBER: Respond with JSON only. Start with { immediately.` },
            { type: 'input_audio', input_audio: { data: options.audioBase64!, format: options.audioFormat! } },
          ] as unknown as string,
        },
      ],
      temperature: 0.3,
      max_tokens: 1500,
    });

    const content = response.choices[0].message.content || '{}';
    try {
      const parsed = JSON.parse(content);
      return {
        grammarScore: parsed.grammarScore ?? 70,
        grammarErrors: Array.isArray(parsed.grammarErrors) ? parsed.grammarErrors : [],
        vocabularyScore: parsed.vocabularyScore ?? 70,
        vocabularySuggestions: Array.isArray(parsed.vocabularySuggestions) ? parsed.vocabularySuggestions : [],
        relevanceScore: parsed.relevanceScore ?? 80,
        relevanceFeedback: parsed.relevanceFeedback ?? undefined,
        fluencyScore: 0,
        overallFeedback: parsed.overallFeedback ?? 'Good effort!',
        alternativePhrasings: Array.isArray(parsed.alternativePhrasings) ? parsed.alternativePhrasings : [],
        pronunciation: {
          pronunciationScore: parsed.pronunciationScore ?? 70,
          transcribedText: parsed.transcribedText ?? '',
          mispronunciations: Array.isArray(parsed.mispronunciations)
            ? parsed.mispronunciations.map((item: { word?: string; heardAs?: string; correctPronunciation?: string }) => ({
                word: item.word ?? '', heardAs: item.heardAs ?? '', correctPronunciation: item.correctPronunciation ?? '',
              }))
            : [],
          pronunciationFeedback: parsed.pronunciationFeedback ?? '',
        },
      };
    } catch {
      return {
        grammarScore: 70, grammarErrors: [], vocabularyScore: 70,
        vocabularySuggestions: [], relevanceScore: 80, fluencyScore: 0,
        overallFeedback: 'Unable to parse analysis.',
        alternativePhrasings: [],
      };
    }
  }

  // CURSOR: Rich translation with definition, usage examples, and type classification
  async richTranslate(
    text: string,
    learningLanguage: string,
    motherLanguage: string,
    options?: AIOptions
  ): Promise<RichTranslation> {
    if (!this.client) {
      throw new Error('OpenAI client not initialized');
    }

    const prompt = getRichTranslationPrompt(text, learningLanguage, motherLanguage);

    const response = await this.client.chat.completions.create({
      model: options?.model || 'gpt-4o-mini',
      messages: [
        { role: 'system', content: 'You are a language learning assistant providing detailed translations. Respond only with valid JSON.' },
        { role: 'user', content: prompt },
      ],
      temperature: 0.3,
      max_tokens: options?.maxTokens ?? 500,
      response_format: { type: 'json_object' },
    });

    const content = response.choices[0].message.content || '{}';
    
    try {
      const parsed = JSON.parse(content);
      return {
        translation: parsed.translation || text,
        type: parsed.type || 'word',
        definition: parsed.definition || '',
        usageExamples: Array.isArray(parsed.usageExamples) ? parsed.usageExamples : [],
        notes: parsed.notes || undefined,
        formality: parsed.formality || 'neutral',
      };
    } catch {
      return {
        translation: text,
        type: 'word',
        definition: '',
        usageExamples: [],
        formality: 'neutral',
      };
    }
  }

  async isAvailable(): Promise<boolean> {
    return !!process.env.OPENAI_API_KEY;
  }

  getStatus(): AIProviderStatus {
    return this.status;
  }
}

// Export singleton instance
export const openAIAssistantProvider = new OpenAIAssistantProvider();
