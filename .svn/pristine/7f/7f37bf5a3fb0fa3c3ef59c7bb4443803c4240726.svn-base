'use client';

import { useEffect, useState } from 'react';
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '@/components/ui/card';
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@/components/ui/select';
import { Badge } from '@/components/ui/badge';
import { useSettingsStore } from '@/stores/settingsStore';

interface ModelInfo {
  id: string;
  name: string;
  description: string;
  contextWindow?: number;
}

const AI_PROVIDERS = [
  { 
    id: 'openai-chat', 
    name: 'OpenAI (Chat)', 
    description: 'Chat Completions API - We manage history', 
    type: 'cloud',
    modes: ['chat'],
  },
  { 
    id: 'openai-assistant', 
    name: 'OpenAI (Assistants)', 
    description: 'Assistants API - OpenAI manages history', 
    type: 'cloud',
    modes: ['assistant'],
  },
  { 
    id: 'ollama', 
    name: 'Ollama (Local)', 
    description: 'Local server - Free, requires Ollama installed', 
    type: 'local',
    modes: ['chat'],
  },
  { 
    id: 'webllm', 
    name: 'WebLLM (Browser)', 
    description: 'Runs in browser via WebGPU - Free, no server needed', 
    type: 'local',
    modes: ['chat'],
  },
];

// CURSOR: Get cost estimate based on provider and model
function getCostEstimate(provider: string, model: string): string {
  if (provider === 'ollama' || provider === 'webllm') {
    return 'Free - runs locally on your device';
  }
  
  // CURSOR: OpenAI pricing (approximate, check openai.com/pricing for current rates)
  if (model.includes('audio')) {
    return 'Audio model - check openai.com/pricing for current rates';
  }
  if (model.startsWith('gpt-4o-mini')) {
    return '~$0.15 per 1M input tokens, ~$0.60 per 1M output tokens';
  }
  if (model.startsWith('gpt-4o')) {
    return '~$2.50 per 1M input tokens, ~$10 per 1M output tokens';
  }
  if (model.startsWith('gpt-4.5')) {
    return '~$75 per 1M input tokens, ~$150 per 1M output tokens';
  }
  if (model.startsWith('gpt-5')) {
    return 'Check openai.com/pricing for current rates';
  }
  if (model.startsWith('gpt-4-turbo')) {
    return '~$10 per 1M input tokens, ~$30 per 1M output tokens';
  }
  if (model.startsWith('gpt-4')) {
    return '~$30 per 1M input tokens, ~$60 per 1M output tokens';
  }
  if (model.startsWith('gpt-3.5')) {
    return '~$0.50 per 1M input tokens, ~$1.50 per 1M output tokens';
  }
  
  return 'Check openai.com/pricing for current rates';
}

// CURSOR: Static models for local providers (no API to query)
const LOCAL_MODELS: Record<string, ModelInfo[]> = {
  'ollama': [
    { id: 'llama3.2', name: 'Llama 3.2', description: 'Latest Llama model' },
    { id: 'llama3.1', name: 'Llama 3.1', description: 'Previous Llama model' },
    { id: 'mistral', name: 'Mistral', description: 'Fast and capable' },
    { id: 'gemma2', name: 'Gemma 2', description: 'Google Gemma model' },
    { id: 'qwen2.5', name: 'Qwen 2.5', description: 'Alibaba Qwen model' },
  ],
  'webllm': [
    { id: 'Llama-3.2-1B-Instruct-q4f32_1-MLC', name: 'Llama 3.2 1B', description: 'Tiny, fast (~500MB)' },
    { id: 'Llama-3.2-3B-Instruct-q4f32_1-MLC', name: 'Llama 3.2 3B', description: 'Small, balanced (~1.5GB)' },
    { id: 'Qwen2.5-1.5B-Instruct-q4f32_1-MLC', name: 'Qwen 2.5 1.5B', description: 'Multilingual (~800MB)' },
    { id: 'SmolLM2-1.7B-Instruct-q4f32_1-MLC', name: 'SmolLM2 1.7B', description: 'Efficient (~900MB)' },
    { id: 'Phi-3.5-mini-instruct-q4f32_1-MLC', name: 'Phi 3.5 Mini', description: 'Microsoft model (~2GB)' },
  ],
};

export function AIProviderSelector() {
  const { ai, setAISettings } = useSettingsStore();
  const [openaiModels, setOpenaiModels] = useState<ModelInfo[]>([]);
  const [loadingModels, setLoadingModels] = useState(false);
  const [modelsError, setModelsError] = useState<string | null>(null);

  // CURSOR: Fetch OpenAI models dynamically
  useEffect(() => {
    const isOpenAIProvider = ai.provider === 'openai-chat' || ai.provider === 'openai-assistant';
    
    if (isOpenAIProvider) {
      setLoadingModels(true);
      setModelsError(null);
      
      fetch('/api/models')
        .then(res => res.json())
        .then(data => {
          if (data.error) {
            setModelsError(data.error);
            setOpenaiModels([]);
          } else {
            setOpenaiModels(data.models || []);
          }
        })
        .catch(err => {
          console.error('[AIProviderSelector] Failed to fetch models:', err);
          setModelsError('Failed to fetch models');
          setOpenaiModels([]);
        })
        .finally(() => setLoadingModels(false));
    }
  }, [ai.provider]);

  // CURSOR: Use dynamic models for OpenAI, static for local providers
  const isOpenAIProvider = ai.provider === 'openai-chat' || ai.provider === 'openai-assistant';
  const models = isOpenAIProvider ? openaiModels : (LOCAL_MODELS[ai.provider] || []);

  return (
    <Card>
      <CardHeader>
        <CardTitle>AI Settings</CardTitle>
        <CardDescription>
          Configure AI provider and model for conversations
        </CardDescription>
      </CardHeader>
      <CardContent className="space-y-4">
        {/* AI Provider */}
        <div className="space-y-2">
          <label className="text-sm font-medium">AI Provider</label>
          <Select
            value={ai.provider}
            onValueChange={(value) => {
              setAISettings({ provider: value });
              // CURSOR: Reset model when provider changes - use local models for non-OpenAI
              const isOpenAI = value === 'openai-chat' || value === 'openai-assistant';
              if (!isOpenAI) {
                const newModels = LOCAL_MODELS[value] || [];
                if (newModels.length > 0) {
                  setAISettings({ model: newModels[0].id });
                }
              }
              // CURSOR: For OpenAI, model will be selected after fetch completes
            }}
          >
            <SelectTrigger>
              <SelectValue placeholder="Select AI provider" />
            </SelectTrigger>
            <SelectContent>
              {AI_PROVIDERS.map((provider) => (
                <SelectItem key={provider.id} value={provider.id}>
                  <div className="flex items-center gap-2">
                    <span>{provider.name}</span>
                    <Badge variant="outline" className="text-xs">
                      {provider.type}
                    </Badge>
                  </div>
                </SelectItem>
              ))}
            </SelectContent>
          </Select>
          <p className="text-xs text-muted-foreground">
            {AI_PROVIDERS.find(p => p.id === ai.provider)?.description}
          </p>
        </div>

        {/* Model selection */}
        <div className="space-y-2">
          <label className="text-sm font-medium">Model</label>
          {loadingModels ? (
            <div className="h-10 flex items-center px-3 border rounded-md bg-muted">
              <span className="text-sm text-muted-foreground">Loading models...</span>
            </div>
          ) : modelsError ? (
            <div className="p-3 border border-destructive/50 rounded-md bg-destructive/10">
              <p className="text-sm text-destructive">{modelsError}</p>
              <p className="text-xs text-muted-foreground mt-1">
                Check your API key configuration
              </p>
            </div>
          ) : models.length > 0 ? (
            <Select
              value={ai.model}
              onValueChange={(value) => setAISettings({ model: value })}
            >
              <SelectTrigger>
                <SelectValue placeholder="Select model" />
              </SelectTrigger>
              <SelectContent>
                {models.map((model) => (
                  <SelectItem key={model.id} value={model.id}>
                    <div className="flex flex-col">
                      <span>{model.name}</span>
                      <span className="text-xs text-muted-foreground">
                        {model.description}
                      </span>
                    </div>
                  </SelectItem>
                ))}
              </SelectContent>
            </Select>
          ) : (
            <div className="h-10 flex items-center px-3 border rounded-md bg-muted">
              <span className="text-sm text-muted-foreground">No models available</span>
            </div>
          )}
        </div>

        {/* Cost estimate */}
        <div className="p-3 bg-muted rounded-lg">
          <h4 className="text-sm font-medium mb-1">Estimated Cost</h4>
          <p className="text-xs text-muted-foreground">
            {getCostEstimate(ai.provider, ai.model)}
          </p>
        </div>
      </CardContent>
    </Card>
  );
}
