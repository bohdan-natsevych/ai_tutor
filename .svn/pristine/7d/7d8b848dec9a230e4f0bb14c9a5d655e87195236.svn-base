'use client';

import { useState, useEffect, useCallback, useRef } from 'react';
import { Button } from '@/components/ui/button';
import { useChatStore } from '@/stores/chatStore';
import { sttManager } from '@/lib/stt/manager';

interface VoiceRecorderProps {
  // CURSOR: Simplified - onSend is called when recording stops with final transcript
  onSend: (transcript: string) => void;
  disabled?: boolean;
  language?: string;
  dialect?: string;
  className?: string;
}

export function VoiceRecorder({
  onSend,
  disabled = false,
  language = 'en',
  dialect = 'american',
  className = '',
}: VoiceRecorderProps) {
  const [isInitialized, setIsInitialized] = useState(false);
  const [error, setError] = useState<string | null>(null);
  // CURSOR: Use selectors for better performance
  const isRecording = useChatStore((state) => state.isRecording);
  const transcript = useChatStore((state) => state.transcript);
  const setRecording = useChatStore((state) => state.setRecording);
  const setTranscript = useChatStore((state) => state.setTranscript);
  
  // CURSOR: Track accumulated transcript from all segments
  // Web Speech API sends results per segment - we need to combine them
  const accumulatedTranscriptRef = useRef('');
  const currentInterimRef = useRef('');

  // Initialize STT
  useEffect(() => {
    const init = async () => {
      try {
        await sttManager.initialize();
        setIsInitialized(true);
      } catch (e) {
        setError('Failed to initialize speech recognition');
        console.error(e);
      }
    };
    init();
  }, []);

  // Set up event handlers
  useEffect(() => {
    if (!isInitialized) return;

    // CURSOR: Accumulate transcript from all speech segments
    // When user pauses, Web Speech API finalizes current segment and starts new one
    // We need to accumulate all finalized segments + current interim
    sttManager.onResult = (result) => {
      if (result.isFinal) {
        // Add finalized segment to accumulated transcript
        accumulatedTranscriptRef.current += result.transcript + ' ';
        currentInterimRef.current = '';
      } else {
        // Update current interim (not finalized yet)
        currentInterimRef.current = result.transcript;
      }
      
      // Show full transcript (accumulated + current interim)
      const fullTranscript = (accumulatedTranscriptRef.current + currentInterimRef.current).trim();
      setTranscript(fullTranscript);
    };

    sttManager.onError = (err) => {
      setError(err.message);
      setRecording(false);
    };

    return () => {
      sttManager.onResult = null;
      sttManager.onError = null;
      sttManager.onStart = null;
      sttManager.onEnd = null;
    };
  }, [isInitialized, setRecording, setTranscript]);

  const startRecording = useCallback(() => {
    setError(null);
    // Reset accumulated transcript
    accumulatedTranscriptRef.current = '';
    currentInterimRef.current = '';
    setTranscript('');
    setRecording(true);
    sttManager.startListening({ language, dialect });
  }, [language, dialect, setRecording, setTranscript]);

  // CURSOR: Send full accumulated transcript when recording stops
  const stopRecording = useCallback(() => {
    sttManager.stopListening();
    setRecording(false);
    
    // Combine accumulated + any remaining interim text
    const finalTranscript = (accumulatedTranscriptRef.current + currentInterimRef.current).trim();
    
    if (finalTranscript) {
      onSend(finalTranscript);
    }
    
    // Reset for next recording
    accumulatedTranscriptRef.current = '';
    currentInterimRef.current = '';
    setTranscript('');
  }, [setRecording, setTranscript, onSend]);

  if (error) {
    return (
      <div className={`flex items-center gap-2 text-destructive text-sm ${className}`}>
        <span>{error}</span>
        <Button variant="ghost" size="sm" onClick={() => setError(null)}>
          Retry
        </Button>
      </div>
    );
  }

  return (
    <div className={`flex flex-col gap-2 ${className}`}>
      {/* Recording indicator with transcript preview */}
      {isRecording && (
        <div className="flex items-center gap-2 p-3 bg-muted rounded-lg animate-pulse">
          <div className="h-3 w-3 bg-red-500 rounded-full animate-pulse" />
          <span className="text-sm flex-1 truncate">
            {transcript || 'Listening...'}
          </span>
        </div>
      )}

      {/* Record button */}
      <Button
        onClick={isRecording ? stopRecording : startRecording}
        disabled={!isInitialized || disabled}
        variant={isRecording ? 'destructive' : 'default'}
        size="lg"
        className="w-full gap-2"
      >
        {isRecording ? (
          <>
            <StopIcon className="h-5 w-5" />
            Stop Recording
          </>
        ) : (
          <>
            <MicIcon className="h-5 w-5" />
            Start Recording
          </>
        )}
      </Button>
    </div>
  );
}

// Icons
function MicIcon({ className }: { className?: string }) {
  return (
    <svg
      xmlns="http://www.w3.org/2000/svg"
      viewBox="0 0 24 24"
      fill="currentColor"
      className={className}
    >
      <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm-1-9c0-.55.45-1 1-1s1 .45 1 1v6c0 .55-.45 1-1 1s-1-.45-1-1V5z" />
      <path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z" />
    </svg>
  );
}

function StopIcon({ className }: { className?: string }) {
  return (
    <svg
      xmlns="http://www.w3.org/2000/svg"
      viewBox="0 0 24 24"
      fill="currentColor"
      className={className}
    >
      <path d="M6 6h12v12H6z" />
    </svg>
  );
}
